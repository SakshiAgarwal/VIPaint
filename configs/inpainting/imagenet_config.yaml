data:
  name: ldm.data.imagenet.ImageNetValidation
  seq: {'half': [200, 300], 'box': [300, 350], 'random': [400,500]} #[400,500] #[350, 450], #, 'val': "random" : [350, 450], half : , val: [0,50]
  file_seq: None
  file_name: ldm/data/Imagenet_valid_new2.npz  #
  channels: 3
  image_size: 256
  latent_size: 64
  latent_channels: 3

autoencoder: /scratch/sakshi/diffusion_inpainting/models/first_stage_models/vq-f4/config.yaml
diffusion: configs/latent-diffusion/cin256-v2.yaml
diffusion_model: /scratch/sakshi/diffusion_inpainting/models/ldm/cin256-v2/model.ckpt
working_dir: results/imagenet
conditional_model: True
  
name: inpainting

measurement:
  operator:
    in_shape: !!python/tuple [1, 3, 256, 256]
    scale_factor: 4
  
  noise: 
    name: gaussian
    sigma: 0.05

mask_opt:
  mask_type: half #random
  mask_len_range: !!python/tuple [64, 65]  # for box
  mask_prob_range: !!python/tuple [0.2, 0.21]  # [0.3, 0.7] for random
  image_size: 256

mask_files: {'random': masks/mask_100_imagenet.npy, "half": masks/mask_random_half_100_imagenet.npy, 
              "box": masks/box_100_imagenet.npy } # validation files : {'random': masks/mask_20_imagenet.npy, "half": masks/mask_random_half_20_imagenet.npy } 

posterior: "gauss" #hierarchical, gauss
name: ldm.guided_diffusion.loss_vq.VQLPIPSWithDiscriminator

gauss: 
  first_stage: vq
  unconditional_guidance_scale: 1
  eta: 0.2 
  beta: 200 
  batch_size: 5
  iterations: 100
  t_steps_hierarchy:  [400] 
  rho: 7
  lr_init_gamma: 0.01
  mean_scale : 1
  mean_scale_top: 0.8

hierarchical: 
  first_stage: vq
  unconditional_guidance_scale: 1
  eta: 0.2 
  beta_1: 100 #70 #700, prior
  beta_2: 100 #70 #700, posterior
  batch_size: 5
  iterations: 50 #250
  t_steps_hierarchy: [550, 400]  #  500, 450,  500, 450, 500, 450, 
  rho: 7
  lr_init_gamma: 0.01
  mean_scale : 1
  mean_scale_top: 0.8 

init:
  var_scale: 0.7
  prior_scale: 5 # 4

sampling:
  method: ps
  scale:  2
  n_samples: 10
  unconditional_guidance_scale: 3

